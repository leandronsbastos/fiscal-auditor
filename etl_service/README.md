# Servi√ßo ETL - Documentos Fiscais

## üìã Vis√£o Geral

Este √© um servi√ßo ETL (Extract, Transform, Load) completo e independente para processamento de arquivos XML de NF-e e NFC-e. O servi√ßo extrai todos os campos dos documentos fiscais e os armazena em um banco de dados PostgreSQL, criando um datalake estruturado.

## üéØ Caracter√≠sticas

- **Extra√ß√£o Completa**: L√™ todos os campos dispon√≠veis nos XMLs de NF-e e NFC-e
- **Datalake Estruturado**: Armazena dados em tabelas relacionais normalizadas
- **Processamento em Lote**: Capaz de processar grandes volumes de arquivos
- **Controle de Duplicatas**: Detecta e ignora documentos j√° processados
- **Logs Detalhados**: Registra todo o hist√≥rico de processamento
- **Independente**: Funciona de forma aut√¥noma, separado do sistema principal

## üèóÔ∏è Arquitetura

### Estrutura do Servi√ßo

```
etl_service/
‚îú‚îÄ‚îÄ __init__.py           # Inicializa√ß√£o do m√≥dulo
‚îú‚îÄ‚îÄ database.py           # Configura√ß√£o do banco de dados
‚îú‚îÄ‚îÄ models.py             # Modelos SQLAlchemy (datalake)
‚îú‚îÄ‚îÄ extractor.py          # Extra√ß√£o de dados dos XMLs
‚îú‚îÄ‚îÄ transformer.py        # Transforma√ß√£o dos dados
‚îú‚îÄ‚îÄ loader.py             # Carregamento no banco de dados
‚îî‚îÄ‚îÄ pipeline.py           # Pipeline completo de ETL
```

### Fluxo de Dados

```
XML Files ‚Üí Extractor ‚Üí Transformer ‚Üí Loader ‚Üí PostgreSQL
                                                    ‚Üì
                                                Datalake
```

## üìä Modelo de Dados

O datalake √© composto pelas seguintes tabelas principais:

### Tabela: `nfe`
Armazena dados principais da NF-e/NFC-e:
- Identifica√ß√£o (chave, n√∫mero, s√©rie, modelo)
- Emitente (CNPJ, raz√£o social, endere√ßo)
- Destinat√°rio (CNPJ, raz√£o social, endere√ßo)
- Totalizadores (valores, impostos)
- Transporte
- Pagamento
- XML completo

### Tabela: `nfe_item`
Armazena itens das notas fiscais:
- Produtos (c√≥digo, descri√ß√£o, NCM, CEST)
- Quantidades e valores
- Impostos detalhados (ICMS, IPI, PIS, COFINS)
- Importa√ß√£o

### Tabela: `nfe_duplicata`
Armazena duplicatas/parcelas:
- N√∫mero da duplicata
- Data de vencimento
- Valor

### Tabelas de Controle
- `etl_processamento`: Registros de execu√ß√µes do ETL
- `etl_log_processamento`: Log detalhado de cada arquivo processado

## üöÄ Instala√ß√£o

### 1. Instalar Depend√™ncias

```bash
pip install sqlalchemy psycopg2-binary lxml
```

### 2. Configurar Banco de Dados

Por padr√£o, o servi√ßo usa:
```
postgresql://postgres:postgres@localhost:5432/fiscal_datalake
```

Para usar outra configura√ß√£o, defina a vari√°vel de ambiente:
```bash
set ETL_DATABASE_URL=postgresql://usuario:senha@host:porta/banco
```

### 3. Inicializar o Banco

```bash
python run_etl.py --init-db
```

Isso criar√° todas as tabelas necess√°rias no banco de dados.

## üíª Uso

### Linha de Comando

#### Processar um Diret√≥rio Completo

```bash
python run_etl.py --diretorio "C:\XMLs\2024"
```

#### Processar sem Recurs√£o (apenas pasta principal)

```bash
python run_etl.py --diretorio "C:\XMLs\2024" --no-recursivo
```

#### Processar Arquivos Espec√≠ficos

```bash
python run_etl.py --arquivos "nota1.xml" "nota2.xml" "nota3.xml"
```

#### Ver Todas as Op√ß√µes

```bash
python run_etl.py --help
```

### Uso Program√°tico

```python
from etl_service.pipeline import ETLPipeline, inicializar_banco

# Inicializar banco (primeira vez)
inicializar_banco()

# Criar pipeline
pipeline = ETLPipeline()

# Processar um diret√≥rio
stats = pipeline.processar_diretorio(
    diretorio="C:/XMLs/2024",
    tipo_processamento="completo",
    recursivo=True
)

print(f"Processados: {stats['processados']}")
print(f"Erros: {stats['erros']}")
```

### Processar Arquivo √önico

```python
from etl_service.pipeline import ETLPipeline

pipeline = ETLPipeline()
resultado = pipeline.processar_arquivo("caminho/para/nota.xml")

if resultado['sucesso']:
    print(f"Sucesso! Chave: {resultado['chave_acesso']}")
else:
    print(f"Erro: {resultado['mensagem']}")
```

## üìà Monitoramento

### Consultar Processamentos

```sql
-- Ver hist√≥rico de processamentos
SELECT 
    id,
    data_processamento,
    tipo_processamento,
    status,
    arquivos_processados,
    arquivos_erro,
    tempo_execucao
FROM etl_processamento
ORDER BY data_processamento DESC;
```

### Consultar Logs Detalhados

```sql
-- Ver log de processamento de arquivos
SELECT 
    data_hora,
    arquivo,
    chave_acesso,
    status,
    mensagem,
    tempo_processamento
FROM etl_log_processamento
WHERE status = 'erro'
ORDER BY data_hora DESC;
```

### Consultar NF-es Processadas

```sql
-- Ver √∫ltimas notas processadas
SELECT 
    chave_acesso,
    numero_nota,
    serie,
    data_emissao,
    emitente_razao_social,
    destinatario_razao_social,
    valor_total_nota,
    data_processamento_etl
FROM nfe
ORDER BY data_processamento_etl DESC
LIMIT 100;
```

### Estat√≠sticas

```sql
-- Estat√≠sticas gerais
SELECT 
    COUNT(*) as total_notas,
    SUM(valor_total_nota) as valor_total,
    COUNT(DISTINCT emitente_cnpj) as total_emitentes,
    COUNT(DISTINCT destinatario_cnpj) as total_destinatarios,
    MIN(data_emissao) as data_mais_antiga,
    MAX(data_emissao) as data_mais_recente
FROM nfe;

-- Total por m√™s
SELECT 
    DATE_TRUNC('month', data_emissao) as mes,
    COUNT(*) as quantidade,
    SUM(valor_total_nota) as valor_total
FROM nfe
GROUP BY DATE_TRUNC('month', data_emissao)
ORDER BY mes DESC;
```

## üîß Configura√ß√µes Avan√ßadas

### Vari√°veis de Ambiente

- `ETL_DATABASE_URL`: URL de conex√£o do banco de dados
- Exemplo: `postgresql://user:pass@localhost:5432/datalake`

### Personaliza√ß√£o do Extrator

O extrator pode ser estendido para capturar campos adicionais:

```python
from etl_service.extractor import XMLExtractor

class CustomExtractor(XMLExtractor):
    def extrair_nfe(self, caminho_arquivo):
        dados = super().extrair_nfe(caminho_arquivo)
        # Adicionar extra√ß√µes customizadas
        dados['campo_custom'] = self._extrair_campo_custom(root)
        return dados
```

## üêõ Troubleshooting

### Erro de Conex√£o com Banco

```
Erro: could not connect to server
```
**Solu√ß√£o**: Verifique se o PostgreSQL est√° rodando e as credenciais est√£o corretas.

### Erro ao Processar XML

```
Erro ao extrair dados do XML
```
**Solu√ß√£o**: Verifique se o arquivo √© um XML v√°lido de NF-e. Use um validador XML.

### Duplicatas n√£o Detectadas

```
IntegrityError: duplicate key value
```
**Solu√ß√£o**: A chave de acesso j√° existe. O sistema normalmente detecta isso, mas se ocorrer o erro, verifique a constraint no banco.

## üìù Exemplos de Consultas √öteis

### Buscar por CNPJ

```sql
-- Buscar todas as notas de um emitente
SELECT * FROM nfe WHERE emitente_cnpj = '12345678000190';

-- Buscar todas as compras de um destinat√°rio
SELECT * FROM nfe WHERE destinatario_cnpj = '12345678000190';
```

### An√°lise de Produtos

```sql
-- Produtos mais vendidos
SELECT 
    descricao,
    COUNT(*) as quantidade_vendas,
    SUM(valor_total_bruto) as valor_total
FROM nfe_item
GROUP BY descricao
ORDER BY quantidade_vendas DESC
LIMIT 20;
```

### An√°lise de Impostos

```sql
-- Total de impostos por tipo
SELECT 
    SUM(valor_icms) as total_icms,
    SUM(valor_ipi) as total_ipi,
    SUM(valor_pis) as total_pis,
    SUM(valor_cofins) as total_cofins
FROM nfe;
```

## üîÑ Integra√ß√£o com Sistema Principal

O servi√ßo ETL √© independente mas pode ser integrado:

```python
# No sistema principal
from etl_service.pipeline import ETLPipeline

def importar_xmls(diretorio):
    pipeline = ETLPipeline()
    return pipeline.processar_diretorio(diretorio)
```

## üìä Performance

- **Velocidade**: ~2-5 arquivos/segundo (depende da complexidade)
- **Mem√≥ria**: ~50-100MB para processamento normal
- **Lotes**: Commits a cada 100 registros por padr√£o

## üõ°Ô∏è Seguran√ßa

- Todas as transa√ß√µes s√£o at√¥micas
- Logs de auditoria completos
- XML original preservado para confer√™ncia
- Detec√ß√£o autom√°tica de duplicatas

## ü§ù Contribuindo

Para adicionar novos campos ao datalake:

1. Atualizar `models.py` com novos campos
2. Atualizar `extractor.py` para extrair os campos
3. Atualizar `transformer.py` para transformar os dados
4. Executar migra√ß√£o do banco

## üìÑ Licen√ßa

Este servi√ßo faz parte do sistema Fiscal Auditor.

## üìû Suporte

Para d√∫vidas ou problemas:
- Consulte a documenta√ß√£o completa
- Verifique os logs de processamento
- Revise as mensagens de erro detalhadas

---

**Vers√£o**: 1.0.0
**√öltima Atualiza√ß√£o**: Janeiro 2026
